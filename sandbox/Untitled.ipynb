{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from scipy import linalg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1992)\n",
    "np.random.seed(1992)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PyTorch uses tensors in format [samples,  channels, size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 1)\n",
      "(2947, 128, 9) (2947, 1)\n",
      "(7352, 128, 9) (7352, 1) (2947, 128, 9) (2947, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, _, _ = utils.load_dataset()\n",
    "trainX = torch.tensor(trainX, dtype=torch.float32)[0, :, 0].view(1, 1, 128)\n",
    "trainy = torch.tensor(trainy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tensor(size, kernel_size, identity=False):\n",
    "    coords = []\n",
    "    vals = []\n",
    "    s = size\n",
    "    if identity:\n",
    "        s = size - 1\n",
    "    for k in range(s):\n",
    "        for j in range(kernel_size):\n",
    "            i = k - j + 1\n",
    "            if k in range(s) and i in range(s) and j in range(kernel_size):\n",
    "                coords.append([k, i, j])\n",
    "                vals.append(1)\n",
    "\n",
    "    if identity:\n",
    "        coords.append([s, s, kernel_size])\n",
    "        vals.append(1)\n",
    "        i = torch.LongTensor(coords)\n",
    "        v = torch.FloatTensor(vals)\n",
    "        return torch.sparse.FloatTensor(i.t(), v, torch.Size([size, size, kernel_size+1]))        \n",
    "                \n",
    "    i = torch.LongTensor(coords)\n",
    "    v = torch.FloatTensor(vals)\n",
    "    return torch.sparse.FloatTensor(i.t(), v, torch.Size([size, size, kernel_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_tensor(5, 3, True).to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic conv1d module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ### PRE-DENSE LAYERS ###\n",
    "        self.conv = nn.Conv1d(1, 1, 3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.conv.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8485, 0.5086, 0.5030, 0.5044, 0.5049, 0.5008, 0.5041, 0.5031,\n",
       "          0.5035, 0.5051, 0.5032, 0.5046, 0.5036, 0.5038, 0.5046, 0.5032,\n",
       "          0.5046, 0.5042, 0.5048, 0.5055, 0.5039, 0.5050, 0.5046, 0.5039,\n",
       "          0.5039, 0.5033, 0.5043, 0.5040, 0.5037, 0.5040, 0.5030, 0.5029,\n",
       "          0.5040, 0.5048, 0.5039, 0.5035, 0.5044, 0.5039, 0.5042, 0.5053,\n",
       "          0.5044, 0.5031, 0.5010, 0.5008, 0.5035, 0.5052, 0.5041, 0.5021,\n",
       "          0.5020, 0.5042, 0.5056, 0.5045, 0.5024, 0.5033, 0.5061, 0.5053,\n",
       "          0.5045, 0.5057, 0.5042, 0.5018, 0.5018, 0.5022, 0.5017, 0.5033,\n",
       "          0.5065, 0.5059, 0.5038, 0.5047, 0.5049, 0.5039, 0.5036, 0.5032,\n",
       "          0.5029, 0.5031, 0.5033, 0.5034, 0.5035, 0.5034, 0.5027, 0.5028,\n",
       "          0.5038, 0.5034, 0.5028, 0.5036, 0.5033, 0.5035, 0.5046, 0.5042,\n",
       "          0.5043, 0.5051, 0.5054, 0.5054, 0.5045, 0.5032, 0.5029, 0.5029,\n",
       "          0.5014, 0.5029, 0.5078, 0.5070, 0.5034, 0.5039, 0.5038, 0.5033,\n",
       "          0.5044, 0.5039, 0.5037, 0.5042, 0.5038, 0.5039, 0.5040, 0.5033,\n",
       "          0.5030, 0.5029, 0.5036, 0.5049, 0.5060, 0.5054, 0.5028, 0.5030,\n",
       "          0.5047, 0.5038, 0.5037, 0.5042, 0.5033, 0.5036, 0.5051, 0.0330]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.forward(trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic custom convolution module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, w):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.w = w.T\n",
    "        self.T = build_tensor(128, 3).to_dense()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.weights = torch.matmul(self.T, self.w)[:, :, 0]\n",
    "        x = torch.matmul(x, self.weights)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8485, 0.5086, 0.5030, 0.5044, 0.5049, 0.5008, 0.5041, 0.5031,\n",
       "          0.5035, 0.5051, 0.5032, 0.5046, 0.5036, 0.5038, 0.5046, 0.5032,\n",
       "          0.5046, 0.5042, 0.5048, 0.5055, 0.5039, 0.5050, 0.5046, 0.5039,\n",
       "          0.5039, 0.5033, 0.5043, 0.5040, 0.5037, 0.5040, 0.5030, 0.5029,\n",
       "          0.5040, 0.5048, 0.5039, 0.5035, 0.5044, 0.5039, 0.5042, 0.5053,\n",
       "          0.5044, 0.5031, 0.5010, 0.5008, 0.5035, 0.5052, 0.5041, 0.5021,\n",
       "          0.5020, 0.5042, 0.5056, 0.5045, 0.5024, 0.5033, 0.5061, 0.5053,\n",
       "          0.5045, 0.5057, 0.5042, 0.5018, 0.5018, 0.5022, 0.5017, 0.5033,\n",
       "          0.5065, 0.5059, 0.5038, 0.5047, 0.5049, 0.5039, 0.5036, 0.5032,\n",
       "          0.5029, 0.5031, 0.5033, 0.5034, 0.5035, 0.5034, 0.5027, 0.5028,\n",
       "          0.5038, 0.5034, 0.5028, 0.5036, 0.5033, 0.5035, 0.5046, 0.5042,\n",
       "          0.5043, 0.5051, 0.5054, 0.5054, 0.5045, 0.5032, 0.5029, 0.5029,\n",
       "          0.5014, 0.5029, 0.5078, 0.5070, 0.5034, 0.5039, 0.5038, 0.5033,\n",
       "          0.5044, 0.5039, 0.5037, 0.5042, 0.5038, 0.5039, 0.5040, 0.5033,\n",
       "          0.5030, 0.5029, 0.5036, 0.5049, 0.5060, 0.5054, 0.5028, 0.5030,\n",
       "          0.5047, 0.5038, 0.5037, 0.5042, 0.5033, 0.5036, 0.5051, 0.0330]]],\n",
       "       grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customModel = CustomNet(model.get_weights())\n",
    "customModel.forward(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(model.forward(trainX) == customModel.forward(trainX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CustomConvolution adding \"identity element\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNetConv(nn.Module):\n",
    "    def __init__(self, w):\n",
    "        super(CustomNetConv, self).__init__()\n",
    "        self.weight = nn.Parameter(w.T)\n",
    "        self.weight.\n",
    "        self.T = build_tensor(129, 3, True).to_dense()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.W = torch.matmul(self.T, torch.cat([self.weight, torch.tensor([[1]])]))[:, :, 0]\n",
    "        #### TODO ajustar ordem: torch.matmul(torch.matmul(self.B, self.W), x)\n",
    "        x = torch.matmul(x, self.W)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8485, 0.5086, 0.5030, 0.5044, 0.5049, 0.5008, 0.5041, 0.5031,\n",
       "          0.5035, 0.5051, 0.5032, 0.5046, 0.5036, 0.5038, 0.5046, 0.5032,\n",
       "          0.5046, 0.5042, 0.5048, 0.5055, 0.5039, 0.5050, 0.5046, 0.5039,\n",
       "          0.5039, 0.5033, 0.5043, 0.5040, 0.5037, 0.5040, 0.5030, 0.5029,\n",
       "          0.5040, 0.5048, 0.5039, 0.5035, 0.5044, 0.5039, 0.5042, 0.5053,\n",
       "          0.5044, 0.5031, 0.5010, 0.5008, 0.5035, 0.5052, 0.5041, 0.5021,\n",
       "          0.5020, 0.5042, 0.5056, 0.5045, 0.5024, 0.5033, 0.5061, 0.5053,\n",
       "          0.5045, 0.5057, 0.5042, 0.5018, 0.5018, 0.5022, 0.5017, 0.5033,\n",
       "          0.5065, 0.5059, 0.5038, 0.5047, 0.5049, 0.5039, 0.5036, 0.5032,\n",
       "          0.5029, 0.5031, 0.5033, 0.5034, 0.5035, 0.5034, 0.5027, 0.5028,\n",
       "          0.5038, 0.5034, 0.5028, 0.5036, 0.5033, 0.5035, 0.5046, 0.5042,\n",
       "          0.5043, 0.5051, 0.5054, 0.5054, 0.5045, 0.5032, 0.5029, 0.5029,\n",
       "          0.5014, 0.5029, 0.5078, 0.5070, 0.5034, 0.5039, 0.5038, 0.5033,\n",
       "          0.5044, 0.5039, 0.5037, 0.5042, 0.5038, 0.5039, 0.5040, 0.5033,\n",
       "          0.5030, 0.5029, 0.5036, 0.5049, 0.5060, 0.5054, 0.5028, 0.5030,\n",
       "          0.5047, 0.5038, 0.5037, 0.5042, 0.5033, 0.5036, 0.5051, 0.0330,\n",
       "          1.0000]]], grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat([trainX[0, 0, :], torch.tensor([1])]).view(1, 1, 129)\n",
    "customModelConv = CustomNetConv(model.get_weights())\n",
    "customModelConv.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(customModelConv.forward(X)[:, :, :-1] == model.forward(trainX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CustomConvolution adding \"identity element\" and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ### PRE-DENSE LAYERS ###\n",
    "        self.conv1 = nn.Conv1d(1, 1, 3, padding=1, bias=False)\n",
    "        self.activ1 = nn.Tanh()\n",
    "        self.conv2 = nn.Conv1d(1, 1, 3, padding=1, bias=False)\n",
    "        self.activ2 = nn.Tanh()\n",
    "        ### DENSE LAYERS ###\n",
    "        self.flat = nn.Flatten(1,-1)\n",
    "        self.dense1 = nn.Linear(128, 100)\n",
    "        self.activ3 = nn.Tanh()\n",
    "        self.dense2 = nn.Linear(100, 6)\n",
    "        self.activ4 = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activ1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activ2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.activ3(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.activ4(x)\n",
    "        return x\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.conv.weight[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
